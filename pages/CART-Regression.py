import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns

# Configuraci贸n de la p谩gina
st.set_page_config(page_title="rbol de Regresi贸n")
st.title("An谩lisis de rbol de Regresi贸n ")

df = pd.read_csv("csv/gym_members_exercise_tracking.csv")
st.subheader("Datos Cargados:")
st.write(df)

categorical_features = ["Gender", "Workout_Type"]
numerical_features = [
    "Age", "Weight (kg)", "Height (m)", "Max_BPM", "Avg_BPM",
    "Resting_BPM", "Session_Duration (hours)", "Fat_Percentage",
    "Water_Intake (liters)", "Workout_Frequency (days/week)", "Experience_Level", "BMI"
]
target = "Calories_Burned"

X = df[categorical_features + numerical_features]
y = df[target]

ct = ColumnTransformer(
    transformers=[("encoder", OneHotEncoder(drop="first"), categorical_features)],
    remainder="passthrough"
)
X = ct.fit_transform(X)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Entrenar el modelo de rbol de Regresi贸n
tree_model = DecisionTreeRegressor(max_depth=5, min_samples_split=10, random_state=42)
tree_model.fit(X_train, y_train)
y_pred_tree = tree_model.predict(X_test)

# M茅tricas para el rbol de Regresi贸n
mse_tree = mean_squared_error(y_test, y_pred_tree)
rmse_tree = np.sqrt(mse_tree)
mae_tree = mean_absolute_error(y_test, y_pred_tree)
r2_tree = r2_score(y_test, y_pred_tree)

# Entrenar el modelo de Regresi贸n Lineal
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
y_pred_linear = linear_model.predict(X_test)

# M茅tricas para la Regresi贸n Lineal
mse_linear = mean_squared_error(y_test, y_pred_linear)
rmse_linear = np.sqrt(mse_linear)
mae_linear = mean_absolute_error(y_test, y_pred_linear)
r2_linear = r2_score(y_test, y_pred_linear)

# Crear un DataFrame con las m茅tricas de comparaci贸n
comparison_data = {
    "M茅trica": [
        "Error Cuadr谩tico Medio (MSE)",
        "Ra铆z del Error Cuadr谩tico Medio (RMSE)",
        "Error Absoluto Medio (MAE)",
        "Coeficiente de Determinaci贸n (R虏)"
    ],
    "rbol de Decisi贸n": [
        f"{mse_tree:.2f}",
        f"{rmse_tree:.2f}",
        f"{mae_tree:.2f}",
        f"{r2_tree:.2f}"
    ],
    "Regresi贸n Lineal": [
        f"{mse_linear:.2f}",
        f"{rmse_linear:.2f}",
        f"{mae_linear:.2f}",
        f"{r2_linear:.2f}"
    ]
}

comparison_df = pd.DataFrame(comparison_data)
# Mostrar la tabla en Streamlit
st.subheader("Comparaci贸n de Resultados entre Modelos")
st.dataframe(comparison_df)
st.write('La regresi贸n lineal m煤ltiple es m谩s eficiente en este caso porque los datos tienen una relaci贸n predominantemente lineal con la variable objetivo, lo que permite que este modelo capture mejor las dependencias.')

# Gr谩fico del rbol
st.subheader("Visualizaci贸n del rbol de Decisi贸n")
from sklearn.tree import plot_tree
fig2, ax2 = plt.subplots(figsize=(20, 10))
plot_tree(tree_model, filled=True, feature_names=ct.get_feature_names_out(), ax=ax2)
st.pyplot(fig2)

from sklearn.tree import export_text
tree_rules = export_text(tree_model, feature_names=ct.get_feature_names_out())
with st.expander("Transcripci贸n del 谩rbol"):
    st.text(tree_rules)

# Comparaci贸n visual de valores reales y predicciones
st.subheader("Comparaci贸n de Valores Reales y Predicciones")
fig, ax = plt.subplots(figsize=(10, 6))
ax.scatter(y_test, y_pred_tree, alpha=0.7, color='blue', label='rbol de Decisi贸n')
ax.scatter(y_test, y_pred_linear, alpha=0.7, color='green', label='Regresi贸n Lineal')
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
ax.set_xlabel("Valores Reales")
ax.set_ylabel("Predicciones")
ax.legend()
ax.set_title("Comparaci贸n de Modelos")
st.pyplot(fig)

# Entrada personalizada para predicci贸n
st.sidebar.header("Predicci贸n Personalizada")
input_values = []

# Agregar entrada para cada caracter铆stica
for feature in numerical_features:
    input_values.append(
        st.sidebar.number_input(f"{feature}", value=float(df[feature].mean()))
    )

# Seleccionar categor铆as para las variables categ贸ricas
for cat in categorical_features:
    unique_values = df[cat].unique()
    selected = st.sidebar.selectbox(f"Selecciona {cat}", unique_values)
    input_values.append(selected)  # Pasar el texto original

if st.sidebar.button("Predecir"):
    try:
        input_df = pd.DataFrame([input_values], columns=numerical_features + categorical_features)
        for col in categorical_features:
            input_df[col] = input_df[col].astype(str)
        input_transformed = ct.transform(input_df)
        input_scaled = scaler.transform(input_transformed)
        tree_prediction = tree_model.predict(input_scaled)
        linear_prediction = linear_model.predict(input_scaled)
        st.subheader("Resultado de la Predicci贸n: Regression Tree")
        st.write(f"Calor铆as quemadas estimadas: **{tree_prediction[0]:.2f}**")
        st.subheader("Resultado de la Predicci贸n: Linear Regression")
        st.write(f"Calor铆as quemadas estimadas: **{linear_prediction[0]:.2f}**")
    except Exception as e:
        st.error(f"Error durante la predicci贸n: {e}")